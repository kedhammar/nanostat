{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Playground notebook for using BeautifulSoup to parse ONT run .html report files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import re\n",
    "from pandas import DataFrame\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_stats(soup, class_name, result_index = 0):\n",
    "    ''' Search bs4 object for HTML class occurence and return list of strings '''\n",
    "    \n",
    "    s = soup.find_all(\"div\", class_=class_name)[result_index].text\n",
    "    \n",
    "    l = [e.strip() for e in s.split(\"\\n\") if e.strip()]\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_barcodes(soup):\n",
    "    ''' Search bs4 object for \"barcode\" class occurence and return dict of barcode counts '''\n",
    "    \n",
    "    bcs = soup.find_all(\"div\", class_=\"barcode\")\n",
    "\n",
    "    if bcs:\n",
    "        unsorted = {}\n",
    "        for bc in bcs:\n",
    "            s = bc.text.strip()\n",
    "\n",
    "            p = re.compile(\"\\d+\")\n",
    "            bc_name, bc_count = s[0:9], p.search(s[10:]).group()\n",
    "            unsorted[bc_name] = bc_count\n",
    "            bc_dict = OrderedDict(sorted(unsorted.items()))\n",
    "        return bc_dict\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_curation(total):\n",
    "    ''' \n",
    "    Takes an unformated list of scrape results and curates it into a dictionary.\n",
    "    \n",
    "    This is a highly manual process due to the varied formatting between keys and values in the report.\n",
    "    '''\n",
    "\n",
    "    # Remove lines that are headers or superfluent\n",
    "    to_remove = ['DATA OUTPUT',\n",
    "                'Data written to disk',\n",
    "                'BASECALLING',\n",
    "                'Pass',\n",
    "                'Fail',\n",
    "                'RUN DURATION',\n",
    "                'RUN SETUP',\n",
    "                'RUN SETTINGS',\n",
    "                'DATA OUTPUT SETTINGS',\n",
    "                'SOFTWARE VERSIONS']\n",
    "    for i in to_remove:\n",
    "        total.remove(i)\n",
    "\n",
    "\n",
    "    # Manually re-shuffle lines pertaining to Q score threshold and pass/fail\n",
    "    p = re.compile(\"min Q score\\: [\\d]+\")\n",
    "    q_score = p.search(\"\".join(total)).group()[13:]\n",
    "\n",
    "    i = total.index(f'Bases called (min Q score: {q_score})')\n",
    "    total[i] = 'Bases passed'\n",
    "    total.insert(i+2, 'Bases failed')\n",
    "    total.insert(i, \"Q score\")\n",
    "    total.insert(i+1, q_score)\n",
    "\n",
    "\n",
    "    # Curate based on whether key-value pairs in the list are...\n",
    "\n",
    "    # 1)\n",
    "    two_lines = total[:-5]\n",
    "    data = {key : val for key, val in zip(two_lines[::2], two_lines[1::2])}\n",
    "    # 2)\n",
    "    missing_keys = total[-5:-1]\n",
    "    keys = [\"Run duration\",\n",
    "            \"Experiment name\",\n",
    "            \"Sample name\",\n",
    "            \"Instrument position\"]\n",
    "    for k, v in zip(keys, missing_keys):\n",
    "        data[k] = v\n",
    "    # 3)\n",
    "    one_line = total[-1]\n",
    "    data[one_line.split(\": \")[0]] = one_line.split(\": \")[1]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Main\" function\n",
    "\n",
    "def get_data(report):\n",
    "    ''' \n",
    "    Takes an ONT .html run report and returns a dictionary containing relevant data.\n",
    "    \n",
    "    Barcode counts are appended as last dictionary entry as an ordered dict if applicable.\n",
    "    '''\n",
    "\n",
    "    soup = bs(open(report, \"r\"),\"html.parser\")\n",
    "\n",
    "    total = []                                                     # List element(s) are...\n",
    "    total += scrape_stats(soup, \"accordion content\", 0)             # Headers, keys or values\n",
    "    total += scrape_stats(soup, \"accordion content\", 1)             # -||-\n",
    "    total += scrape_stats(soup, \"run-details\")[0].split(\" · \")      # Values w/o keys, separated by \" · \"\n",
    "    total += scrape_stats(soup, \"protocol-run-id\")                  # Key : Value\n",
    "\n",
    "    data = manual_curation(total)\n",
    "\n",
    "    # Check for barcodes, and add read count dict, if any\n",
    "    barcodes = scrape_barcodes(soup)\n",
    "    if barcodes:\n",
    "        data[\"barcode_reads\"] = barcodes\n",
    "\n",
    "    return data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 ('alfred')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0fe7c1456621898fb2537deb4ea7bf4ba13838aecd2d50f2219ad663306032e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
