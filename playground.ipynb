{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Playground notebook for using BeautifulSoup to parse ONT run .html report files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uses\n",
    "- [Beautiful Soup](https://realpython.com/beautiful-soup-web-scraper-python/#step-3-parse-html-code-with-beautiful-soup)\n",
    "- re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import re\n",
    "\n",
    "soup = bs(open(\"run_reports/report.html\",\"r\"),\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N50\n",
    "q_n50 = soup.find_all(\"div\", class_=\"basecalling-statistics\")[0].text\n",
    "p_n50 = re.compile('[0-9.]+ \\Db')\n",
    "s_n50 = p_n50.search(q_n50).group()\n",
    "\n",
    "# Flow cell type, ID and kit\n",
    "q_fc_kit = soup.find_all(\"div\", class_=\"accordion content\")[0].text\n",
    "p_fc_id = re.compile(\"\\D\\D\\D\\d\\d\\d\\d\\d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run details\n",
    "soup.find_all(\"div\", class_=\"run-details\")[0].text\n",
    "\n",
    "# run id\n",
    "soup.find_all(\"div\", class_=\"protocol-run-id\")[0].text\n",
    "\n",
    "# reads pass Gb, reads fail Gb\n",
    "soup.find_all(\"div\", class_=\"container basecalling\")[0].text\n",
    "\n",
    "\n",
    "\n",
    "# est bases Gb, data prod Gb, Reads M, Estimated N50 kb\n",
    "soup.find_all(\"div\", class_=\"accordion content\")[0].text\n",
    "\n",
    "# fc type, fc id, kit type\n",
    "soup.find_all(\"div\", class_=\"accordion content\")[2].text\n",
    "\n",
    "# run length, active channel bool, pore scan freh hrs, bias init, bias final, reserved bool, basecalling method\n",
    "soup.find_all(\"div\", class_=\"accordion content\")[3].text\n",
    "\n",
    "# fast5 op, fast5 rpf, fastq op, etc ... , data location(!)\n",
    "soup.find_all(\"div\", class_=\"accordion content\")[4].text\n",
    "\n",
    "# software versions\n",
    "soup.find_all(\"div\", class_=\"accordion content\")[5].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_stats(soup, class_name, result_index = 0):\n",
    "    '''Search bs4 object for HTML class occurence and return list of strings'''\n",
    "    s = soup.find_all(\"div\", class_=class_name)[result_index].text\n",
    "    l = [e.strip() for e in s.split(\"\\n\") if e.strip()]\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def list2dict_pairs(l):\n",
    "    ''' [key1, val1, key2, val2, ... ] ---> {key1:val1, key2:val2, ... } '''\n",
    "    assert len(l) % 2 == 0\n",
    "    d = {}\n",
    "    for i in range(0, len(l), 2):\n",
    "        d[l[i]] = l[i+1]\n",
    "    return d\n",
    "\n",
    "def stats2dict(l):\n",
    "    '''\n",
    "    Disentangle list from scrape_stats() to dict.\n",
    "    \n",
    "    Input has to match format\n",
    "    [HEADER_A, key1, val1, key2, val2, HEADER_B...]\n",
    "\n",
    "    Output becomes\n",
    "    --> {HEADER_A: {key1:val1, key2:val2}, HEADER_B...}\n",
    "    '''\n",
    "\n",
    "    p = re.compile(\"[A-Z ]{7,}\")\n",
    "    s = \"\\n\".join(l)\n",
    "    headers = p.findall(s)\n",
    "\n",
    "    d = {}\n",
    "    start_index = 0\n",
    "    for header in headers[1:]:\n",
    "        try:\n",
    "            next_index = l.index(header)\n",
    "        except IndexError:\n",
    "            next_index = len(l)\n",
    "        d[header] = list2dict_pairs(l[start_index+1:next_index])\n",
    "        start_index = next_index\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FYI\n",
    "total = []\n",
    "\n",
    "# Headers followed by pairs\n",
    "total += scrape_stats(soup, \"accordion content\", 0) # Remove \"written to disk\" and shuffle some lines\n",
    "total += scrape_stats(soup, \"accordion content\", 1)\n",
    "\n",
    "# Values w/o keys\n",
    "total += scrape_stats(soup, \"run-details\")[0].split(\" Â· \")\n",
    "\n",
    "# Key : Value\n",
    "total += scrape_stats(soup, \"protocol-run-id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MANUALLY curate list\n",
    "to_remove = ['DATA OUTPUT',\n",
    "             'Data written to disk',\n",
    "             'BASECALLING',\n",
    "             'Pass',\n",
    "             'Fail',\n",
    "             'RUN DURATION',\n",
    "             'RUN SETUP',\n",
    "             'RUN SETTINGS',\n",
    "             'DATA OUTPUT SETTINGS',\n",
    "             'SOFTWARE VERSIONS']\n",
    "\n",
    "for i in to_remove:\n",
    "    total.remove(i)\n",
    "\n",
    "# TODO q threshold\n",
    "i = total.index('Bases called (min Q score: 9)')\n",
    "total[i] = 'Bases pass (min Q score: 9)'\n",
    "total.insert(i+2, 'Bases fail (min Q score: 9)')\n",
    "\n",
    "## Curate based on whether key-value pairs in the list are \n",
    "# - on consecutive lines \n",
    "# - missing keys\n",
    "# - concatenated\n",
    "two_lines, missing_keys, one_line = total[:-5], total[-5:-1], total[-1]\n",
    "\n",
    "data = {key : val for key, val in zip(two_lines[::2], two_lines[1::2])}\n",
    "\n",
    "keys = [\"Run duration\",\n",
    "        \"Run folder\",\n",
    "        \"Sample name\",\n",
    "        \"Instrument position\"]\n",
    "for k, v in zip(keys, missing_keys):\n",
    "    data[k] = v\n",
    "\n",
    "data[one_line.split(\": \")[0]] = one_line.split(\": \")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 ('alfred')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0fe7c1456621898fb2537deb4ea7bf4ba13838aecd2d50f2219ad663306032e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
